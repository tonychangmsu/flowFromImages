{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Activation, Dense, Dropout, Flatten, Conv2D,\\\n",
    "                        BatchNormalization, Concatenate, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from src.analysis_tools import plot_confusion_matrix, extract_data\n",
    "from src.cnn_models import simple_cnn, dense_cnn, coeff_determination, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if zip file has been downloaded locally\n",
    "#f = glob('/content/data/*.zip')\n",
    "#extract_data(f[0], '/content/img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.array([f.split('_')[1] for f in glob('/content/img/flowImages/*_m.jpg')])\n",
    "im_list = np.array((glob('/content/img/flowImages/*_m.jpg')))[np.argsort(dates)]\n",
    "x = [Image.open(i) for i in im_list]\n",
    "size = x[0].size\n",
    "#need to image resize to be consistent\n",
    "x = np.array([np.array(im.resize(size)) for im in x])\n",
    "flowdata = pd.read_csv('/content/data/flowData.csv')\n",
    "#aggregate to the mean flowrate for the day\n",
    "y = flowdata[flowdata['dates'].isin(dates)].flow.values\n",
    "#we need another classification of ytrain. Let's just do 2 categories hi vs lo\n",
    "#print(np.histogram(y, bins=30))\n",
    "#print(np.median(y),np.mean(y))\n",
    "#let's just pick the median as the middle point\n",
    "#threshold = np.median(ytrain)\n",
    "lower_threshold = np.percentile(y,15)\n",
    "upper_threshold = np.percentile(y,85)\n",
    "y_lower = (y<=lower_threshold)\n",
    "y_mid = ((y>lower_threshold) & (y<upper_threshold))\n",
    "y_upper = (y>=upper_threshold)\n",
    "yclass = np.moveaxis(np.array([y_lower, y_mid,y_upper]).astype('int8'), 0,-1)\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.arange(3),\n",
    "                                                 np.argmax(yclass, axis=1))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "i_s = np.random.choice(len(x), len(x), replace=False)\n",
    "train_perc = 0.8\n",
    "train_i = i_s[:int(len(x)*train_perc)]\n",
    "test_i = i_s[int(len(x)*train_perc):]\n",
    "\n",
    "dates_train = dates[train_i]\n",
    "dates_test = dates[test_i]\n",
    "x_train = x[train_i]\n",
    "x_test = x[test_i]/255.\n",
    "y_train_flow = y[train_i] \n",
    "y_test_flow = y[test_i]\n",
    "y_train = yclass[train_i]\n",
    "y_test = yclass[test_i]\n",
    "\n",
    "input_shape = x.shape[1:]\n",
    "output_shape = yclass.shape[1]\n",
    "\n",
    "print(np.bincount(np.argmax(y_train, axis=1)))\n",
    "print(np.bincount(np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 7 \n",
    "r_range = 5 \n",
    "batch_size = 8 \n",
    "brightness_range=(0.8,1)\n",
    "datagen = ImageDataGenerator(rescale=1./255,\\\n",
    "                             rotation_range=r_range,\\\n",
    "                             width_shift_range=shift,\\\n",
    "                             height_shift_range=shift,\\\n",
    "                             brightness_range=brightness_range)\n",
    "datagen.fit(x_train, augment=True, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = next(datagen.flow(x_train,y_train, batch_size))\n",
    "f, ax = plt.subplots(1,batch_size, figsize=(20,10))\n",
    "for i in range(batch_size):\n",
    "    ax[i].imshow(z[0][i])\n",
    "    ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dense_cnn(input_shape=input_shape, n_dblocks=3, output_shape=output_shape)\n",
    "#model = simple_cnn(input_shape=input_shape, output_shape=output_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "epochs = 10 \n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "acc_hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size), \\\n",
    "                               steps_per_epoch=len(x_train)/batch_size, \\\n",
    "                               epochs=epochs, \\\n",
    "                               class_weight=class_weights,\\\n",
    "                               validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hist:\n",
    "    hist_add = acc_hist.history\n",
    "    for k in hist.keys():\n",
    "        hist[k].extend(hist_add[k])\n",
    "else:\n",
    "    hist = acc_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hist = acc_hist.history\n",
    "f, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "for k in hist.keys():\n",
    "    if 'loss' in k:\n",
    "        ax[0].plot(hist[k], label=k)\n",
    "    else:\n",
    "        ax[1].plot(hist[k], label=k)\n",
    "ylabels = ['Loss', 'Accuracy']\n",
    "for i in range(2):\n",
    "    ax[i].legend()\n",
    "    ax[i].grid(alpha=0.5)\n",
    "    ax[i].set_ylabel(ylabels[i])\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "f.savefig('/content/output/accuracy.png', dpi=100, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "ii = 7 \n",
    "jj = 7\n",
    "sample_i = np.random.choice(len(x_test), ii*jj, replace=False).reshape((ii,jj))\n",
    "label = ['low flow','mid flow','high flow']\n",
    "color = ['orange', 'darkblue']\n",
    "f,ax = plt.subplots(ii, jj, figsize=(18,30))\n",
    "for i in range(ii):\n",
    "    for j in range(jj):\n",
    "        s = sample_i[i][j]\n",
    "        ax[i][j].imshow(x_test[s])\n",
    "        ax[i][j].set_axis_off()\n",
    "        ax[i][j].set_title('%s\\nFlowrate: %s\\nTrue:%s\\nPredicted:%s'%(dates_test[s],y_test_flow[s],\\\n",
    "                                             label[np.argmax(y_test[s])],label[np.argmax(y_hat[s])]),\\\n",
    "                                                         color=color[np.argmax(y_test[s])==np.argmax(y_hat[s])])\n",
    "f.savefig('/content/output/validation.png', dpi=100, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(y_hat,axis=1))\n",
    "plot_confusion_matrix(cm, classes=label, outname='/content/output/conf_mat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/content/output/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/content/output/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "plot_model(model, to_file='/content/output/model_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
